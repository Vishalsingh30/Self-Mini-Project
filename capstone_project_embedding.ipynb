{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s7-oG3VwUP5t","executionInfo":{"status":"ok","timestamp":1734161527120,"user_tz":-330,"elapsed":23499,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"a4ec69fc-9af2-4b6b-cbfd-3dadb43fefa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["Path = '/content/drive/MyDrive/MLT+Dataset/Dataset/'"],"metadata":{"id":"yr3Nn3PAUQgo","executionInfo":{"status":"ok","timestamp":1734161527120,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import os\n","from nltk.stem import PorterStemmer"],"metadata":{"id":"ZE-LKmj3vBtj","executionInfo":{"status":"ok","timestamp":1734161535553,"user_tz":-330,"elapsed":8437,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**Step 1: Import and merge all the three datasets**"],"metadata":{"id":"wB7KUKfSaxSz"}},{"cell_type":"code","source":["\n","# Load each English and German file\n","german_files = [\"commoncrawl_de_en.txt\", \"europarl-v7_de_en.txt\", \"news-commentary-v9_de_en.txt\"]\n","english_files = [\"commoncrawl_en_de.txt\", \"europarl-v7_en_de.txt\", \"news-commentary-v9_en_de.txt\"]"],"metadata":{"id":"3bYX41cbUgpH","executionInfo":{"status":"ok","timestamp":1734161535553,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","# Read English and German text files\n","with open(Path + 'commoncrawl_en_de.txt', 'r', encoding='utf-8') as eng_file:\n","    english_sentences = eng_file.readlines()\n","\n","with open(Path + 'commoncrawl_de_en.txt', 'r', encoding='utf-8') as ger_file:\n","    german_sentences = ger_file.readlines()\n","\n","# Strip any unnecessary whitespace (e.g., newline characters)\n","commoncrawl_english_sentences = [sentence.strip() for sentence in english_sentences]\n","commoncrawl_german_sentences = [sentence.strip() for sentence in german_sentences]"],"metadata":{"id":"GNaVM1_-YVCC","executionInfo":{"status":"ok","timestamp":1734161550164,"user_tz":-330,"elapsed":14613,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["if len(commoncrawl_english_sentences) != len(commoncrawl_german_sentences):\n","    raise ValueError(\"The number of sentences in the English and German files do not match.\")"],"metadata":{"id":"X3tRGwWGb87X","executionInfo":{"status":"ok","timestamp":1734161550164,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["commoncrawl_en_de_df = pd.DataFrame({\n","    'English': commoncrawl_english_sentences,\n","    'German': commoncrawl_german_sentences\n","})"],"metadata":{"id":"saFKQuzfcCAq","executionInfo":{"status":"ok","timestamp":1734161550855,"user_tz":-330,"elapsed":693,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["commoncrawl_en_de_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBJcQmmicFKt","executionInfo":{"status":"ok","timestamp":1734161550856,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"dbcfba7c-6bfa-47d0-e408-3f665c2a77c7"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2399123, 2)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# Read English and German text files\n","with open(Path + 'europarl-v7_en_de.txt', 'r', encoding='utf-8') as eng_file:\n","    english_sentences = eng_file.readlines()\n","\n","with open(Path + 'europarl-v7_de_en.txt', 'r', encoding='utf-8') as ger_file:\n","    german_sentences = ger_file.readlines()\n","\n","# Strip any unnecessary whitespace (e.g., newline characters)\n","europarl_english_sentences = [sentence.strip() for sentence in english_sentences]\n","europarl_german_sentences = [sentence.strip() for sentence in german_sentences]"],"metadata":{"id":"MOXbQ5bYcGj4","executionInfo":{"status":"ok","timestamp":1734161559514,"user_tz":-330,"elapsed":8664,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["if len(europarl_english_sentences) != len(europarl_german_sentences):\n","    raise ValueError(\"The number of sentences in the English and German files do not match.\")"],"metadata":{"id":"TzVxUEyhdZqI","executionInfo":{"status":"ok","timestamp":1734161559514,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","europarl_en_de_df = pd.DataFrame({\n","    'English': europarl_english_sentences,\n","    'German': europarl_english_sentences\n","})"],"metadata":{"id":"7VIbwnMldiFw","executionInfo":{"status":"ok","timestamp":1734161560249,"user_tz":-330,"elapsed":737,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["europarl_en_de_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pP6xZnhsbbKl","executionInfo":{"status":"ok","timestamp":1734161560249,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"29dba06a-81b8-422e-dfb3-690728615b6b"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1920209, 2)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Read English and German text files\n","# cleaning data for news comm in german\n","def is_special_characters(line):\n","    return re.match(r'^[^a-zA-Z0-9\\s]+$', line) is not None\n","\n","commentary_english_sentences = []\n","commentary_german_sentences = []\n","\n","with open(Path + 'news-commentary-v9_en_de.txt', 'r', encoding='utf-8') as file:\n","  for line in file:\n","        cleaned_line = line.strip()\n","\n","        if cleaned_line and not cleaned_line.isdigit() and not is_special_characters(cleaned_line):\n","            # Replace multiple spaces with a single space\n","            cleaned_line = re.sub(r'\\s+', ' ', cleaned_line)\n","            commentary_english_sentences.append(cleaned_line)\n","\n","with open(Path + 'news-commentary-v9_en_de.txt', 'r', encoding='utf-8') as file:\n","  for line in file:\n","        cleaned_line = line.strip()\n","\n","        if cleaned_line and not cleaned_line.isdigit() and not is_special_characters(cleaned_line):\n","            # Replace multiple spaces with a single space\n","            cleaned_line = re.sub(r'\\s+', ' ', cleaned_line)\n","            commentary_german_sentences.append(cleaned_line)"],"metadata":{"id":"-_oDY4EddqnI","executionInfo":{"status":"ok","timestamp":1734161566831,"user_tz":-330,"elapsed":6586,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["if len(commentary_english_sentences) != len(commentary_german_sentences):\n","    raise ValueError(\"The number of sentences in the English and German files do not match.\")"],"metadata":{"id":"_Kgdo_5Pc9sd","executionInfo":{"status":"ok","timestamp":1734161566831,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["commentary_en_de_df = pd.DataFrame({\n","    'English': commentary_english_sentences,\n","    'German': commentary_german_sentences\n","})"],"metadata":{"id":"JtNSJ7DddDxO","executionInfo":{"status":"ok","timestamp":1734161566832,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["commentary_en_de_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9t_PaaeldWdu","executionInfo":{"status":"ok","timestamp":1734161566832,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"ab02a831-876f-4dae-bc90-c5b7938dc358"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(201553, 2)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["final_df = pd.concat([commoncrawl_en_de_df, europarl_en_de_df, commentary_en_de_df], axis=0, ignore_index=True)"],"metadata":{"id":"I-L0K10bdc-m","executionInfo":{"status":"ok","timestamp":1734161566832,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["final_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lLQo-HlpdxIx","executionInfo":{"status":"ok","timestamp":1734161566832,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"706c1151-5dce-4231-b7a0-d4d281ea504e"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4520885, 2)"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["**Step 2: Data cleansing**"],"metadata":{"id":"eOcR8z2FbasV"}},{"cell_type":"code","source":["train_df = final_df.sample(frac=0.007, random_state=12)"],"metadata":{"id":"7AJy4TSkAj4O","executionInfo":{"status":"ok","timestamp":1734163532091,"user_tz":-330,"elapsed":533,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["final_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MsYQXaFEPc1Q","executionInfo":{"status":"ok","timestamp":1734163534113,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"dc512f60-f67b-4eda-c6ea-5f6bfd04bc32"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4520885, 2)"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["def clean_text(text):\n","    # Convert text to lowercase\n","    text = text.lower()\n","    # Remove special characters and punctuation (except apostrophes in contractions)\n","    text = re.sub(r\"[^a-zA-ZäöüßÄÖÜéèàùâêîôûç'\\s]\", '', text)\n","    # Remove extra whitespace\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","# Apply cleaning function to both columns\n","train_df['English'] = train_df['English'].apply(clean_text)\n","train_df['German'] = train_df['German'].apply(clean_text)\n","\n","# Display cleaned DataFrame\n","print(train_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89j_R0lRfV4o","executionInfo":{"status":"ok","timestamp":1734163540522,"user_tz":-330,"elapsed":1048,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"558d9847-8f04-4079-b5cc-70204097af10"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                   English  \\\n","2067265           the counterpart appeared two years later   \n","152051             public parking is available metres away   \n","1684613  we guarantee the return of amount paid for the...   \n","2757674  that question was put to the citizens of switz...   \n","3663922  we welcome that because we the united states n...   \n","...                                                    ...   \n","217733   the bedrooms are very small but are very clean...   \n","2058614  you will reach behy and the camp before youd c...   \n","4438570  santa claus was a turkish dervish who in the m...   \n","21856    always prepared with the freshest ingredients ...   \n","1571836  toolbar contains shortcuts to frequently used ...   \n","\n","                                                    German  \n","2067265         das gegenstück erscheint zwei jahre später  \n","152051   öffentliche parkmöglichkeiten befinden sich in...  \n","1684613  wir garantieren die zurückzahlung der für die ...  \n","2757674  that question was put to the citizens of switz...  \n","3663922  we welcome that because we the united states n...  \n","...                                                    ...  \n","217733   das hotel liegt direkt an einer spurigen straß...  \n","2058614  du kommst nach behy zum campgelände bevor du n...  \n","4438570  santa claus was a turkish dervish who in the m...  \n","21856    andalusiens wählen wir bereiten unsere speisen...  \n","1571836  toolbar enthält verknüpfungen zu häufig verwen...  \n","\n","[31646 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["**Step 3: NLP pre processing - Dataset suitable to be used for AIML model learning**"],"metadata":{"id":"n2R8IGtFbjiV"}},{"cell_type":"code","source":["train_df = train_df.reset_index()"],"metadata":{"id":"KM35qozGm3HG","executionInfo":{"status":"ok","timestamp":1734163542542,"user_tz":-330,"elapsed":3,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"JFZHpxCOAzXu","executionInfo":{"status":"ok","timestamp":1734163544123,"user_tz":-330,"elapsed":23,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"9bb9ce67-4a2c-466f-e389-9af981020c61"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     index                                            English  \\\n","0  2067265           the counterpart appeared two years later   \n","1   152051            public parking is available metres away   \n","2  1684613  we guarantee the return of amount paid for the...   \n","3  2757674  that question was put to the citizens of switz...   \n","4  3663922  we welcome that because we the united states n...   \n","\n","                                              German  \n","0         das gegenstück erscheint zwei jahre später  \n","1  öffentliche parkmöglichkeiten befinden sich in...  \n","2  wir garantieren die zurückzahlung der für die ...  \n","3  that question was put to the citizens of switz...  \n","4  we welcome that because we the united states n...  "],"text/html":["\n","  <div id=\"df-1a6a6a5f-e613-4c44-96f9-d11441258f0e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>English</th>\n","      <th>German</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2067265</td>\n","      <td>the counterpart appeared two years later</td>\n","      <td>das gegenstück erscheint zwei jahre später</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>152051</td>\n","      <td>public parking is available metres away</td>\n","      <td>öffentliche parkmöglichkeiten befinden sich in...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1684613</td>\n","      <td>we guarantee the return of amount paid for the...</td>\n","      <td>wir garantieren die zurückzahlung der für die ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2757674</td>\n","      <td>that question was put to the citizens of switz...</td>\n","      <td>that question was put to the citizens of switz...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3663922</td>\n","      <td>we welcome that because we the united states n...</td>\n","      <td>we welcome that because we the united states n...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a6a6a5f-e613-4c44-96f9-d11441258f0e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-1a6a6a5f-e613-4c44-96f9-d11441258f0e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-1a6a6a5f-e613-4c44-96f9-d11441258f0e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-353ec466-be6e-45f4-a6a1-ddd7bc735355\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-353ec466-be6e-45f4-a6a1-ddd7bc735355')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-353ec466-be6e-45f4-a6a1-ddd7bc735355 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_df","summary":"{\n  \"name\": \"train_df\",\n  \"rows\": 31646,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1310644,\n        \"min\": 76,\n        \"max\": 4520868,\n        \"num_unique_values\": 31646,\n        \"samples\": [\n          1355350,\n          3785088,\n          41745\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31366,\n        \"samples\": [\n          \"we are tired of private security services and the omnipresent purchase obligation the removal of park benches that forces passersby into cappuccino bars or to just move on\",\n          \"ottima la posizione proprio a due passi dal centro ottima l'accoglienza da parte del personale giovani simpaticiti e disponibilissimi\",\n          \"this organicpsychic syndrome affects the nervous system and can result in serious forms of brain damage\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"German\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31381,\n        \"samples\": [\n          \"die trolle hassten die nachtelfen ein gef\\u00fchl das auch heute noch besteht\",\n          \"all the people from the press in the room downstairs tell me however that mr prodi's spokesman said that if parliament wants this meeting to take place in public it can be\",\n          \"we see examples of innovation in our newspapers each day but the industry as a whole fought against the introduction of catalytic converters wildly exaggerating their cost\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["train_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5dB8SpiGY3Q","executionInfo":{"status":"ok","timestamp":1734163547234,"user_tz":-330,"elapsed":590,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"dec0853e-698f-4f88-a035-c4afa8456823"},"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(31646, 3)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","\n","from nltk.tokenize import word_tokenize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khECX4cx-C0_","executionInfo":{"status":"ok","timestamp":1734163550924,"user_tz":-330,"elapsed":749,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"90320017-2977-46b5-f6c7-9743b26890f6"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":["nltk.download('stopwords')\n","\n","from nltk.corpus import stopwords\n","\n","german_stop_words = stopwords.words('german')\n","english_stop_words = stopwords.words('english')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqB3iDNc-T8B","executionInfo":{"status":"ok","timestamp":1734163550924,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"a11a080b-a373-4a3d-9848-7a1b5ad2410e"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["chunk_size = 500000  # Adjust this based on available memory\n","max_seq_length = 50  # Adjust based on data analysis\n","output_dir = '/content/data1117/preprocessed_chunks_training/'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Initialize tokenizers\n","stemmer = PorterStemmer()\n","english_tokenizer = Tokenizer()\n","german_tokenizer = Tokenizer()\n","\n","# Split the DataFrame into chunks manually\n","num_chunks = len(train_df) // chunk_size + (1 if len(train_df) % chunk_size != 0 else 0)\n","\n","# Step 1: Fit Tokenizers Across Chunks\n","for i in range(num_chunks):\n","    print(\"num_chunk----->\", i)\n","    chunk = train_df.iloc[i * chunk_size:(i + 1) * chunk_size]\n","    chunk['german_tokens'] = chunk['German'].apply(word_tokenize)\n","    chunk['english_tokens'] = chunk['English'].apply(word_tokenize)\n","    chunk['german_tokens'] = chunk['german_tokens'].apply(lambda tokens: [token for token in tokens if token not in german_stop_words])\n","    chunk['english_tokens'] = chunk['english_tokens'].apply(lambda tokens: [token for token in tokens if token not in english_stop_words])\n","\n","    chunk['german_tokens'] = chunk['german_tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n","    chunk['english_tokens'] = chunk['english_tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n","    chunk['German'] = chunk['german_tokens'].apply(lambda tokens: ' '.join(tokens))\n","    chunk['English'] = chunk['english_tokens'].apply(lambda tokens: ' '.join(tokens))\n","\n","    # Update tokenizers\n","    english_tokenizer.fit_on_texts(chunk['English'])\n","    german_tokenizer.fit_on_texts(chunk['German'])\n","\n","    # Convert to sequences\n","    english_sequences = english_tokenizer.texts_to_sequences(chunk['English'])\n","    german_sequences = german_tokenizer.texts_to_sequences(chunk['German'])\n","\n","    # Pad sequences\n","    english_padded = pad_sequences(english_sequences, maxlen=max_seq_length, padding='post')\n","    german_padded = pad_sequences(german_sequences, maxlen=max_seq_length, padding='post')\n","\n","    # Save each chunk\n","    np.save(os.path.join(output_dir, f'english_chunk_{i}.npy'), english_padded)\n","    np.save(os.path.join(output_dir, f'german_chunk_{i}.npy'), german_padded)\n","\n","print(\"Data processing in chunks completed. Tokenized sequences are saved to disk.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"McCsEHNwM83Q","executionInfo":{"status":"ok","timestamp":1734163585585,"user_tz":-330,"elapsed":34179,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"7b6c1e64-0b97-42ae-b60a-6922c1601f3d"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["num_chunk-----> 0\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-60-be82efb5eff6>:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['german_tokens'] = chunk['German'].apply(word_tokenize)\n","<ipython-input-60-be82efb5eff6>:19: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['english_tokens'] = chunk['English'].apply(word_tokenize)\n","<ipython-input-60-be82efb5eff6>:20: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['german_tokens'] = chunk['german_tokens'].apply(lambda tokens: [token for token in tokens if token not in german_stop_words])\n","<ipython-input-60-be82efb5eff6>:21: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['english_tokens'] = chunk['english_tokens'].apply(lambda tokens: [token for token in tokens if token not in english_stop_words])\n","<ipython-input-60-be82efb5eff6>:23: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['german_tokens'] = chunk['german_tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n","<ipython-input-60-be82efb5eff6>:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['english_tokens'] = chunk['english_tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n","<ipython-input-60-be82efb5eff6>:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['German'] = chunk['german_tokens'].apply(lambda tokens: ' '.join(tokens))\n","<ipython-input-60-be82efb5eff6>:26: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  chunk['English'] = chunk['english_tokens'].apply(lambda tokens: ' '.join(tokens))\n"]},{"output_type":"stream","name":"stdout","text":["Data processing in chunks completed. Tokenized sequences are saved to disk.\n"]}]},{"cell_type":"code","source":["# Initialize lists to store all data\n","english_data = []\n","german_data = []\n","output_dir = '/content/data1117/preprocessed_chunks_training/'\n","# Iterate through all saved chunks\n","num_chunks = len([name for name in os.listdir(output_dir) if name.startswith('english_chunk_')])\n","\n","for i in range(num_chunks):\n","    # Load the English and German chunks\n","    english_chunk = np.load(os.path.join(output_dir, f'english_chunk_{i}.npy'))\n","    german_chunk = np.load(os.path.join(output_dir, f'german_chunk_{i}.npy'))\n","\n","    # Append to the list\n","    english_data.extend(english_chunk)\n","    german_data.extend(german_chunk)\n","\n","# Convert lists to DataFrame\n","preprocessed_training_data = pd.DataFrame({\n","    'English': english_data,\n","    'German': german_data\n","})\n","\n","print(\"Combined DataFrame created successfully.\")\n","print(preprocessed_training_data.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2inGit1MX16j","executionInfo":{"status":"ok","timestamp":1734163585585,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"b0f364b3-d05e-480c-95af-e2732781e3fe"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Combined DataFrame created successfully.\n","                                             English  \\\n","0  [3683, 573, 61, 18, 710, 0, 0, 0, 0, 0, 0, 0, ...   \n","1  [88, 391, 115, 1314, 451, 0, 0, 0, 0, 0, 0, 0,...   \n","2  [429, 552, 507, 1376, 30, 0, 0, 0, 0, 0, 0, 0,...   \n","3  [80, 178, 223, 1692, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n","4  [276, 197, 8, 17, 801, 2641, 1406, 102, 20, 14...   \n","\n","                                              German  \n","0  [14086, 2496, 265, 129, 1091, 0, 0, 0, 0, 0, 0...  \n","1  [1478, 11006, 946, 309, 2497, 0, 0, 0, 0, 0, 0...  \n","2  [3409, 14087, 235, 21266, 6471, 0, 0, 0, 0, 0,...  \n","3  [6, 127, 196, 3, 1, 191, 2, 7122, 0, 0, 0, 0, ...  \n","4  [10, 417, 6, 90, 10, 1, 282, 33, 51, 990, 3410...  \n"]}]},{"cell_type":"code","source":["preprocessed_training_data.to_parquet('/content/drive/MyDrive/capstone_preprocess_training.parquet')"],"metadata":{"id":"35gKhDymrfDT","executionInfo":{"status":"ok","timestamp":1734163585585,"user_tz":-330,"elapsed":8,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":["**Step 4: Design, train and test simple RNN**"],"metadata":{"id":"XnVzEMFMb3jx"}},{"cell_type":"code","source":["train_df = pd.read_parquet('/content/drive/MyDrive/capstone_preprocess_training.parquet')"],"metadata":{"id":"hBwlZ0ZwzH-l","executionInfo":{"status":"ok","timestamp":1734163585586,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["train_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOp5mgjg2fGs","executionInfo":{"status":"ok","timestamp":1734163585586,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"8530b099-a977-430e-d443-1b62de2022bf"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(31646, 2)"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","import numpy as np\n","\n","# Step 1: Custom Dataset Class\n","class SequenceDataset(Dataset):\n","    def __init__(self, df, input_col, target_col, input_max_len=None, target_max_len=None):\n","        self.input_sequences = self.pad_sequences(df[input_col].tolist(), max_length=input_max_len)\n","        self.target_sequences = self.pad_sequences(df[target_col].tolist(), max_length=target_max_len)\n","\n","    def pad_sequences(self, sequences, max_length=None):\n","        valid_sequences = [seq for seq in sequences if len(seq) > 0]\n","        if max_length is None:\n","            max_length = max(len(seq) for seq in valid_sequences)\n","        return np.array(\n","            valid_sequences, dtype=np.int64\n","        )\n","\n","    def __len__(self):\n","        return len(self.input_sequences)\n","\n","    def __getitem__(self, idx):\n","        return (\n","            torch.tensor(self.input_sequences[idx], dtype=torch.long),\n","            torch.tensor(self.target_sequences[idx], dtype=torch.long),\n","        )\n","\n","# Load and preprocess data\n","# Assume df is a Pandas DataFrame with \"English\" and \"German\" columns\n","input_max_len = 50  # Set maximum sequence lengths\n","target_max_len = 50\n","train_dataset = SequenceDataset(train_df, input_col=\"English\", target_col=\"German\", input_max_len=input_max_len, target_max_len=target_max_len)\n","# hold_out_dataset = SequenceDataset(hold_out_df, input_col=\"English\", target_col=\"German\", input_max_len=input_max_len, target_max_len=target_max_len)\n","\n","# DataLoader\n","batch_size = 16\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","\n"],"metadata":{"id":"cVVFkA0bIrSk","executionInfo":{"status":"ok","timestamp":1734163585586,"user_tz":-330,"elapsed":6,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","\n","\n","# Step 2: Define RNN Model with Embeddings\n","class RNNWithEmbedding(nn.Module):\n","    def __init__(self, input_dim, output_dim, embed_dim, hidden_dim, padding_idx):\n","        super(RNNWithEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=padding_idx)\n","        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)  # Embed input tokens\n","        output, _ = self.rnn(embedded)  # RNN layer\n","        output = self.fc(output)  # Fully connected layer\n","        return output\n","\n","# Model parameters\n","input_vocab_size = train_df[\"English\"].apply(lambda x: max(x)).max() + 1\n","output_vocab_size = train_df[\"German\"].apply(lambda x: max(x)).max() + 1\n","embed_dim = 128  # Dimension of word embeddings\n","hidden_dim = 128  # Hidden state dimension\n","padding_idx = 0  # Token for padding\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = RNNWithEmbedding(input_vocab_size, output_vocab_size, embed_dim, hidden_dim, padding_idx).to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss(ignore_index=padding_idx)  # Ignore padding in loss calculation\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Step 3: Training Loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for inputs, targets in train_dataloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Reshape for loss computation\n","        outputs = outputs.view(-1, output_vocab_size)\n","        targets = targets.view(-1)\n","\n","        loss = criterion(outputs, targets)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sk_N9LEQZHTb","executionInfo":{"status":"ok","timestamp":1734169014766,"user_tz":-330,"elapsed":2256146,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"6ef57add-ca11-4334-994a-f69bfd4fbd21"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50, Loss: 8.19080402612445\n","Epoch 2/50, Loss: 7.398646698441616\n","Epoch 3/50, Loss: 6.871127482492352\n","Epoch 4/50, Loss: 6.437763185665027\n","Epoch 5/50, Loss: 6.07901947177698\n","Epoch 6/50, Loss: 5.769907738248788\n","Epoch 7/50, Loss: 5.533795343009478\n","Epoch 8/50, Loss: 5.395364112391149\n","Epoch 9/50, Loss: 5.210550840631414\n","Epoch 10/50, Loss: 5.098154233849567\n","Epoch 11/50, Loss: 4.975869658984116\n","Epoch 12/50, Loss: 4.967288739037586\n","Epoch 13/50, Loss: 4.887492290039757\n","Epoch 14/50, Loss: 4.948541448258534\n","Epoch 15/50, Loss: 4.762877324473629\n","Epoch 16/50, Loss: 4.775150833886844\n","Epoch 17/50, Loss: 4.724256018054256\n","Epoch 18/50, Loss: 4.821493205455244\n","Epoch 19/50, Loss: 4.7493548381196\n","Epoch 20/50, Loss: 4.637461034786352\n","Epoch 21/50, Loss: 4.638160916623501\n","Epoch 22/50, Loss: 4.643048938051153\n","Epoch 23/50, Loss: 4.6637857933015505\n","Epoch 24/50, Loss: 4.687742391056913\n","Epoch 25/50, Loss: 4.825265346571457\n","Epoch 26/50, Loss: 4.627383795980255\n","Epoch 27/50, Loss: 4.612835032151611\n","Epoch 28/50, Loss: 4.729728823845982\n","Epoch 29/50, Loss: 4.664101961890896\n","Epoch 30/50, Loss: 4.596314852592075\n","Epoch 31/50, Loss: 4.5552906745364865\n","Epoch 32/50, Loss: 4.662120117215464\n","Epoch 33/50, Loss: 4.577181494995364\n","Epoch 34/50, Loss: 4.55855885820032\n","Epoch 35/50, Loss: 4.557483672854633\n","Epoch 36/50, Loss: 4.5970190371734185\n","Epoch 37/50, Loss: 4.620867028274961\n","Epoch 38/50, Loss: 4.6534634686336\n","Epoch 39/50, Loss: 4.6162930372631585\n","Epoch 40/50, Loss: 4.634551580441613\n","Epoch 41/50, Loss: 4.742150521977486\n","Epoch 42/50, Loss: 4.747934344444044\n","Epoch 43/50, Loss: 4.890264575715253\n","Epoch 44/50, Loss: 4.653382946434831\n","Epoch 45/50, Loss: 4.563484965007153\n","Epoch 46/50, Loss: 4.602073852164922\n","Epoch 47/50, Loss: 4.623514527136684\n","Epoch 48/50, Loss: 4.705688561419264\n","Epoch 49/50, Loss: 4.631596402765164\n","Epoch 50/50, Loss: 4.689279208168824\n"]}]},{"cell_type":"code","source":["# Step 4: Testing and Evaluation\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","\n","model.eval()\n","bleu_scores = []\n","with torch.no_grad():\n","    for inputs, targets in train_dataloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        predictions = torch.argmax(outputs, dim=2)\n","\n","    smoothing = SmoothingFunction()\n","    for pred, target in zip(predictions.cpu().numpy(), targets.cpu().numpy()):\n","        pred_tokens = [token for token in pred if token != padding_idx]\n","        target_tokens = [token for token in target if token != padding_idx]\n","        bleu_scores.append(sentence_bleu([target_tokens], pred_tokens, smoothing_function=smoothing.method1))\n","\n","print(f\"Average BLEU Score with Smoothing: {np.mean(bleu_scores)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZaB3gF3tZbE9","executionInfo":{"status":"ok","timestamp":1734169027264,"user_tz":-330,"elapsed":12502,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"7c3f977f-8dfa-4289-8324-35a2abd3aa6d"},"execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":["Average BLEU Score with Smoothing: 0.035434258592088964\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","# Step 3: Define the LSTM Model with Embedding\n","class LSTMWithEmbedding(nn.Module):\n","    def __init__(self, input_vocab_size, output_vocab_size, embedding_dim, hidden_dim):\n","        super(LSTMWithEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(input_vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc = nn.Linear(hidden_dim, output_vocab_size)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)  # Convert token IDs to embeddings\n","        output, (hidden, cell) = self.lstm(embedded)  # LSTM forward pass\n","        output = self.fc(output)  # Map to output vocabulary size\n","        return output\n","\n","# Model parameters\n","input_vocab_size = train_df[\"English\"].apply(lambda x: max(x)).max() + 1  # Vocabulary size of English\n","output_vocab_size = train_df[\"German\"].apply(lambda x: max(x)).max() + 1  # Vocabulary size of German\n","embedding_dim = 64\n","hidden_dim = 128\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# Initialize model, loss, and optimizer\n","model = LSTMWithEmbedding(input_vocab_size, output_vocab_size, embedding_dim, hidden_dim).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding index\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Step 4: Training Loop\n","num_epochs = 50\n","for epoch in range(num_epochs):\n","    model.train()\n","    epoch_loss = 0\n","    for inputs, targets in train_dataloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","\n","        # Reshape outputs and targets for loss computation\n","        outputs = outputs.view(-1, output_vocab_size)  # Flatten for CrossEntropyLoss\n","        targets = targets.view(-1)  # Flatten targets\n","\n","        # Compute loss\n","        loss = criterion(outputs, targets)\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(train_dataloader)}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZpQzt1ZpdSK","outputId":"63e31382-ac18-4005-f639-ac3cb4b7b20f","executionInfo":{"status":"ok","timestamp":1734165815359,"user_tz":-330,"elapsed":2229779,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n","Epoch 1/50, Loss: 8.129580169162809\n","Epoch 2/50, Loss: 7.195653106373169\n","Epoch 3/50, Loss: 6.431390816087791\n","Epoch 4/50, Loss: 5.875089645867883\n","Epoch 5/50, Loss: 5.434603942778523\n","Epoch 6/50, Loss: 5.065609554911768\n","Epoch 7/50, Loss: 4.756647158922633\n","Epoch 8/50, Loss: 4.504145090813825\n","Epoch 9/50, Loss: 4.297210356222486\n","Epoch 10/50, Loss: 4.135872913564059\n","Epoch 11/50, Loss: 3.9996648069821426\n","Epoch 12/50, Loss: 3.887211584345757\n","Epoch 13/50, Loss: 3.7855895940888638\n","Epoch 14/50, Loss: 3.7012505068455956\n","Epoch 15/50, Loss: 3.627193490342737\n","Epoch 16/50, Loss: 3.5520575821580493\n","Epoch 17/50, Loss: 3.4912791008655173\n","Epoch 18/50, Loss: 3.430997374445893\n","Epoch 19/50, Loss: 3.3818515721177427\n","Epoch 20/50, Loss: 3.329871272655059\n","Epoch 21/50, Loss: 3.2868714740592138\n","Epoch 22/50, Loss: 3.2454835347627844\n","Epoch 23/50, Loss: 3.2104130215543587\n","Epoch 24/50, Loss: 3.1719611977783564\n","Epoch 25/50, Loss: 3.1377771199653557\n","Epoch 26/50, Loss: 3.1087083269901297\n","Epoch 27/50, Loss: 3.0758917341941046\n","Epoch 28/50, Loss: 3.0497670604558276\n","Epoch 29/50, Loss: 3.021381874959558\n","Epoch 30/50, Loss: 3.000945651495059\n","Epoch 31/50, Loss: 2.9754258215246594\n","Epoch 32/50, Loss: 2.955359197663345\n","Epoch 33/50, Loss: 2.9290964798088384\n","Epoch 34/50, Loss: 2.9089782064435936\n","Epoch 35/50, Loss: 2.8916849040165467\n","Epoch 36/50, Loss: 2.8780080882796626\n","Epoch 37/50, Loss: 2.856183856575024\n","Epoch 38/50, Loss: 2.8374713041543718\n","Epoch 39/50, Loss: 2.823195028895676\n","Epoch 40/50, Loss: 2.806247127128443\n","Epoch 41/50, Loss: 2.791652348272962\n","Epoch 42/50, Loss: 2.779767667499905\n","Epoch 43/50, Loss: 2.765252855417099\n","Epoch 44/50, Loss: 2.7613333557083584\n","Epoch 45/50, Loss: 2.74504815682362\n","Epoch 46/50, Loss: 2.727894336859064\n","Epoch 47/50, Loss: 2.7164242450219436\n","Epoch 48/50, Loss: 2.709290804286818\n","Epoch 49/50, Loss: 2.694836582585461\n","Epoch 50/50, Loss: 2.68951170147972\n"]}]},{"cell_type":"code","source":["# Step 5: Evaluation\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","model.eval()\n","with torch.no_grad():\n","    total_bleu_score = 0\n","    for inputs, targets in train_dataloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","\n","        # Convert logits to predictions\n","        predictions = torch.argmax(outputs, dim=-1)\n","\n","        # Compute BLEU Score\n","        bleu_scores = []\n","        smoothing = SmoothingFunction()\n","        for pred, target in zip(predictions.cpu().numpy(), targets.cpu().numpy()):\n","            pred_tokens = [token for token in pred if token != 0]  # Exclude padding\n","            target_tokens = [token for token in target if token != 0]  # Exclude padding\n","            bleu_scores.append(sentence_bleu([target_tokens], pred_tokens, smoothing_function=smoothing.method1))\n","        total_bleu_score += np.mean(bleu_scores)\n","\n","    print(f\"Average BLEU Score on Holdout: {total_bleu_score / len(train_dataloader)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrVeHzQ0FeT0","executionInfo":{"status":"ok","timestamp":1734166713554,"user_tz":-330,"elapsed":22467,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"3a9fdc75-7e6d-4b44-c30a-2b668812f413"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Average BLEU Score on Holdout: 0.06511842757512007\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"OgRU8jKZBZ7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 4: Testing and Evaluation\n","from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n","\n","\n","model.eval()\n","bleu_scores = []\n","with torch.no_grad():\n","    for inputs, targets in train_dataloader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = model(inputs)\n","        predictions = torch.argmax(outputs, dim=2)\n","\n","    smoothing = SmoothingFunction()\n","    for pred, target in zip(predictions.cpu().numpy(), targets.cpu().numpy()):\n","        pred_tokens = [token for token in pred if token != padding_idx]\n","        target_tokens = [token for token in target if token != padding_idx]\n","        bleu_scores.append(sentence_bleu([target_tokens], pred_tokens, smoothing_function=smoothing.method1))\n","\n","print(f\"Average BLEU Score with Smoothing: {np.mean(bleu_scores)}\")\n"],"metadata":{"id":"94H9R2h7qFLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Saving the RNN model\n","torch.save(model.state_dict(), \"/content/drive/MyDrive/rnn_embedding_model.pth\")"],"metadata":{"id":"KULsAS5kyCwI","executionInfo":{"status":"ok","timestamp":1734170318024,"user_tz":-330,"elapsed":560,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["loaded_model = RNNWithEmbedding(input_vocab_size, output_vocab_size, embed_dim, hidden_dim, padding_idx)\n","loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/rnn_embedding_model.pth\"))\n","loaded_model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCWn9NeQz56Q","executionInfo":{"status":"ok","timestamp":1734170321565,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishal Singh","userId":"10752893921649395524"}},"outputId":"3ca1cd9c-3e9d-4836-a047-b2dd1c913fa2"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-72-100ca2d3ed26>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  loaded_model.load_state_dict(torch.load(\"/content/drive/MyDrive/rnn_embedding_model.pth\"))\n"]},{"output_type":"execute_result","data":{"text/plain":["RNNWithEmbedding(\n","  (embedding): Embedding(33501, 128, padding_idx=0)\n","  (rnn): RNN(128, 128, batch_first=True)\n","  (fc): Linear(in_features=128, out_features=59659, bias=True)\n",")"]},"metadata":{},"execution_count":72}]}]}